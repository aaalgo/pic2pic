#!/usr/bin/env python
from __future__ import absolute_import
from __future__ import division
from __future__ import print_function
import sys
sys.path.append('build/lib.linux-x86_64-2.7')
sys.path.append('tensorflow-vgg')
import os
#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
import time
import threading
import subprocess
import logging
from tqdm import tqdm
import numpy as np
import tensorflow as tf
import cv2
import picpac
import colorize_nets
import _pic2pic
from vgg19 import Vgg19

AB_BINS = 313

flags = tf.app.flags
FLAGS = flags.FLAGS
flags.DEFINE_string('db', 'ilsvrc2015.train', '')
flags.DEFINE_float('learning_rate', 0.02/100, 'initial learning rate.')
flags.DEFINE_bool('decay', True, '')
flags.DEFINE_float('decay_rate', 0.9, '')
flags.DEFINE_float('decay_steps', 10000, '')
flags.DEFINE_string('model', 'model', '')
flags.DEFINE_string('resume', None, '')

flags.DEFINE_integer('batch', 16, '')
flags.DEFINE_integer('max_steps', 400000, '')
flags.DEFINE_integer('epoch_steps', 200, '')
flags.DEFINE_integer('ckpt_epochs', 20, '')
flags.DEFINE_integer('verbose', logging.INFO, '')
flags.DEFINE_integer('max_to_keep', 200, '')

flags.DEFINE_integer('generator_downscale', 0, '')
flags.DEFINE_integer('generator_blocks', 4, '')
flags.DEFINE_integer('generator_upscale', 2, '')

flags.DEFINE_integer('generator_filters', 64, '')
flags.DEFINE_integer('discriminator_size', 32, '')
flags.DEFINE_float('perceptual_weight', 1e0, '')
flags.DEFINE_float('smoothness_weight', 2e5, '')
flags.DEFINE_float('adversary_weight', 5e2, '')

# generate a function that returns parametric ReLU
def p_relu (alpha=0.25):
    return lambda net: tf.nn.relu(net) - alpha * tf.nn.relu(-net)

def generator (net, filters):
    net = slim.conv2d(net, filters, 7, 1, activation_fn=p_relu())
    # downscale
    for _ in range(FLAGS.generator_downscale):
        net = slim.conv2d(net, filters, 4, 2, activation_fn=p_relu())
    # residual block
    for _ in range(FLAGS.generator_blocks):
        residual = slim.conv2d(net, filters, 3, 1, activation_fn=p_relu(alpha=0.1))
        net = residual + net
    # upscale
    for _ in range(FLAGS.generator_upscale):
		# I think subpixel convolution is just conv_transpose
		# http://www.wdong.org/equivalence-of-subpixel-convolution-and-transposed-convolution.html
        net = slim.conv2d_transpose(net, filters, 6, 2, activation_fn=p_relu())
    net = slim.conv2d(net, 3, 7, 1, activation_fn=None)
    return net

# returns two feature vectors, L and H
# L is low-level perceptual feature
# H is high-level discriminative feature, +1: real data; -1: generated data
def feature_extractor (rgb):
    c = FLAGS.discriminator_size
    vgg = Vgg19()
    vgg.build(rgb/255)
    disc1_1 = slim.conv2d(slim.batch_norm(vgg.conv1_2), c, 5, 2, activation_fn=p_relu())
    disc1_2 = slim.conv2d(disc1_2, c, 5, 2)     # 1/4
    disc2 = slim.conv2d(slim.batch_norm(vgg.conv2_2), 2*c, 5, 2, activation_fn=p_relu())    # 1/4
    disc3 = slim.conv2d(slim.batch_norm(vgg.conv3_2), 3*c, 3, 1, activation_fn=p_relu())    # 1/4
    net = tf.concat([disc1_2, disc2, disc3], axis=3)
    net = slim.conv2d(net, 4*c, 1, 1, activation_fn=p_relu())
    net = slim.conv2d(net, 3*c, 3, 2, activation_fn=p_relu())
    net = slim.conv2d(net, 2*c, 1, 1, activation_fn=p_relu())
    disc = slim.batch_norm(slim.conv2d(net, 1, 1, 1, activation_fn=None))
    return vgg.conv2_2, net

def softminus (x):
    return x - tf.nn.softplus(x)

def build_graph (optimizer, global_step):

    zoom = 2**(FLAGS.generator_upscale - FLAGS.generator_downscale)

    # Y: hi-res
    #    holding original samples at train time
    Y = tf.placeholder(tf.float32, shape=(None, None, None, 3), name="images")

    # X: low-res image,
    #    generated by down-sizing hires image at train time
    hi_size = tf.slice(tf.shape(Y), 1, 2)   # (H, W)
    lo_size = lo_size / zoom

    X = tf.image.resize_images(Y, lo_size, name='lo_res')

    G = tf.identify(generator(X, FLAGS.generator_filters), name='hi_res')

    # X and G need to go through the same feature extracting network
    # so we concatenate them first and then split the results
    L, H = feature_extractor(tf.concat([Y, G], axis=0))

    L1, L2 = tf.split(0, 2, L)  # low-level feature,    2 is prediction
    H1, H2 = tf.split(0, 2, H)  # high-level feature,   2 is prediction

    loss_perceptual = tf.reduce_mean(tf.square(L1 - L2), name='pe')

    sub = tf.shape(G) - tf.constant([0, 1, 1, 0], dtype=tf.int32)
    G0 = tf.slice(G, [0, 0, 0, 0], sub)
    Gx = tf.slice(G, [0, 0, 1, 0], sub)
    Gy = tf.slice(G, [0, 1, 0, 0], sub)

    loss_smooth = tf.reduce_mean(tf.pow(tf.square(G - Gx) + tf.square(G - Gy), 1.25), name='sm')

    loss_adversary = tf.identify(1.0 - tf.reduce_mean(softminus(H2)), name='ad')

    loss_discriminator = tf.reduce_mean(softminus(H2) - tf.nn.softplus(H1), name='di')

    loss_G = loss_perceptual * FLAGS.perceptual_weight +
             loss_smooth * FLAGS.smoothness_weight +
             loss_adversary * FLAGS.adversary_weight

    phases = []
    phase.append(('generate',
                  optimizer.minimise(loss_G, global_step=global_step),
                  [loss_perceptual, loss_smooth, loss_adversary],
                  [Y, G]))

    phase.append(('discriminate',
                  optimizer.minimise(loss_discriminator, global_step=global_step),
                  [loss_discriminator],
                  []))

    return Y, phases

def main (_):
    logging.basicConfig(level=FLAGS.verbose)
    try:
        os.makedirs(FLAGS.model)
    except:
        pass
    assert FLAGS.db and os.path.exists(FLAGS.db)

    rate = tf.constant(FLAGS.learning_rate)
    global_step = tf.Variable(0, name='global_step', trainable=False)
    if FLAGS.decay:
        rate = tf.train.exponential_decay(rate, global_step, FLAGS.decay_steps, FLAGS.decay_rate, staircase=True)
        tf.summary.scalar('learning_rate', rate)
    optimizer = tf.train.AdamOptimizer(rate)

    Y, phases = build_graph(optimizer, global_step)

    init = tf.global_variables_initializer()

    tf.get_default_graph().finalize()

    picpac_config = dict(seed=2016,
                cache=False,
                max_size=200,
                min_size=192,
                crop_width=176,
                crop_height=176,
                shuffle=True,
                reshuffle=True,
                batch=FLAGS.batch,
                round_div=stride,
                channels=3,
                stratify=False,
                pert_min_scale=1, #0.92,
                pert_max_scale=1.5,
                channel_first=False # this is tensorflow specific
                                    # Caffe's dimension order is different.
                )

    stream = picpac.ImageStream(FLAGS.db, perturb=False, loop=True, **picpac_config)

    sess_config = tf.ConfigProto()

    with tf.Session(config=sess_config) as sess:
        sess.run(init)
        if FLAGS.resume:
            saver.restore(sess, FLAGS.resume)
        step = 0
        epoch = 0
        global_start_time = time.time()
        while step < FLAGS.max_steps:
            start_time = time.time()
            avg = np.array([0] * len(metric_names), dtype=np.float32)
            for _ in tqdm(range(FLAGS.epoch_steps), leave=False):
                images, _, _ = stream.next()
                forward_dict = {}
                m_off = 0
                for _, train, metrics, forward, show in phases:
                    feed_dict = {Y: images}
                    feed_dict.update(forward_dict)
                    _, m, f = sess.run([train, metrics, forward, show], feed_dict=feed_dict)
                    forward_dict = dict(zip(forward, f))
                    m_off_n = m_off + len(metrics)
                    avg[m_off:m_off_n] += m
                    m_off = m_off_n
                    pass
                step += 1
                pass
            avg /= FLAGS.epoch_steps
            stop_time = time.time()
            txt = ', '.join(['%s=%.4f' % (a, b) for a, b in zip(metric_names, list(avg))])
            print('step %d: elapsed=%.4f time=%.4f %s'
                    % (step, (stop_time - global_start_time), (stop_time - start_time), txt))
            epoch += 1
            if epoch % FLAGS.ckpt_epochs == 0:
                ckpt_path = '%s/%d' % (FLAGS.model, step)
                saver.save(sess, ckpt_path)
                print('epoch %d step %d, saving to %s in %.4fs.' % (epoch, step, ckpt_path, stop_time - start_time))
            pass
        pass
    pass

if __name__ == '__main__':
    tf.app.run()

